{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpcTL4f2G9WE"
      },
      "source": [
        "## Installation of libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwn75S4Ca11c",
        "outputId": "ffd7e8ab-cb56-4e04-a6f5-eacb609619b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/boudinfl/pke.git\n",
            "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-mvmqtm82\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/boudinfl/pke.git /tmp/pip-req-build-mvmqtm82\n",
            "  Resolved https://github.com/boudinfl/pke.git to commit 69871ffdb720b83df23684fea53ec8776fd87e63\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (3.8.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.13.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.2.2)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.3.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (0.18.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (1.4.2)\n",
            "Requirement already satisfied: spacy>=3.2.3 in /usr/local/lib/python3.10/dist-packages (from pke==2.0.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.4.0)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from networkx->pke==2.0.0) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from networkx->pke==2.0.0) (2.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->pke==2.0.0) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->pke==2.0.0) (2023.12.25)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pke==2.0.0) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.2.3->pke==2.0.0) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->pke==2.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->networkx->pke==2.0.0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->networkx->pke==2.0.0) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.2.3->pke==2.0.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.2.3->pke==2.0.0) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy>=3.2.3->pke==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.2.3->pke==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->networkx->pke==2.0.0) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet flashtext==2.7\n",
        "!pip install git+https://github.com/boudinfl/pke.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm7IRHJzzRX5",
        "outputId": "d08bc8f4-4d63-45bd-d5ff-98e654dbe59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.11.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.43.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install h5py\n",
        "!pip install typing-extensions\n",
        "!pip install wheel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM2h7czt2s0f"
      },
      "outputs": [],
      "source": [
        "#!python -m pip install --upgrade pip\n",
        "!pip install --quiet transformers\n",
        "!pip install --quiet sentencepiece\n",
        "!pip install --quiet textwrap3==0.9.2\n",
        "!pip install --quiet gradio==3.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEfmzArJzGOY"
      },
      "outputs": [],
      "source": [
        "!pip install h5py\n",
        "!pip install typing-extensions\n",
        "!pip install wheel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbiUd-SkcDFn"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet strsim==0.0.3\n",
        "!pip install --quiet sense2vec==2.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDHhiuKJ2eva"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJwVkHS-eSnv"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet sentence-transformers==2.2.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a4aKqRxe3-i"
      },
      "source": [
        "The below code restarts the colab notebook. Once it is restarted continue from next section and no need to run this section (installation) again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aA7g4bf84HVb"
      },
      "outputs": [],
      "source": [
        "!pip install scipy==1.13.0\n",
        "!pip install networkx==2.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp7gjW5HfRjL"
      },
      "outputs": [],
      "source": [
        "# restart runtime\n",
        "quit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVBDYRGTAW7"
      },
      "source": [
        "## Example 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRNhJ0wPn_kv"
      },
      "source": [
        "Text taken from:\n",
        "https://gadgets.ndtv.com/internet/news/dogecoin-price-rally-surge-elon-musk-tweet-twitter-working-developers-improve-transaction-efficiency-2442120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qwSTl62XeYS"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt5wyqeq0Pq8",
        "outputId": "fb1f3490-c4e6-4749-e6a3-369c668b4e07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elon Musk has shown again he can influence the digital currency market with just his tweets. After saying that his electric vehicle-making company\n",
            "Tesla will not accept payments in Bitcoin because of environmental concerns, he tweeted that he was working with developers of Dogecoin to improve\n",
            "system transaction efficiency. Following the two distinct statements from him, the world's largest cryptocurrency hit a two-month low, while Dogecoin\n",
            "rallied by about 20 percent. The SpaceX CEO has in recent months often tweeted in support of Dogecoin, but rarely for Bitcoin.  In a recent tweet,\n",
            "Musk put out a statement from Tesla that it was “concerned” about the rapidly increasing use of fossil fuels for Bitcoin (price in India) mining and\n",
            "transaction, and hence was suspending vehicle purchases using the cryptocurrency.  A day later he again tweeted saying, “To be clear, I strongly\n",
            "believe in crypto, but it can't drive a massive increase in fossil fuel use, especially coal”.  It triggered a downward spiral for Bitcoin value but\n",
            "the cryptocurrency has stabilised since.   A number of Twitter users welcomed Musk's statement. One of them said it's time people started realising\n",
            "that Dogecoin “is here to stay” and another referred to Musk's previous assertion that crypto could become the world's future currency.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from textwrap3 import wrap\n",
        "\n",
        "text = \"\"\"Elon Musk has shown again he can influence the digital currency market with just his tweets. After saying that his electric vehicle-making company\n",
        "Tesla will not accept payments in Bitcoin because of environmental concerns, he tweeted that he was working with developers of Dogecoin to improve\n",
        "system transaction efficiency. Following the two distinct statements from him, the world's largest cryptocurrency hit a two-month low, while Dogecoin\n",
        "rallied by about 20 percent. The SpaceX CEO has in recent months often tweeted in support of Dogecoin, but rarely for Bitcoin.  In a recent tweet,\n",
        "Musk put out a statement from Tesla that it was “concerned” about the rapidly increasing use of fossil fuels for Bitcoin (price in India) mining and\n",
        "transaction, and hence was suspending vehicle purchases using the cryptocurrency.  A day later he again tweeted saying, “To be clear, I strongly\n",
        "believe in crypto, but it can't drive a massive increase in fossil fuel use, especially coal”.  It triggered a downward spiral for Bitcoin value but\n",
        "the cryptocurrency has stabilised since.   A number of Twitter users welcomed Musk's statement. One of them said it's time people started realising\n",
        "that Dogecoin “is here to stay” and another referred to Musk's previous assertion that crypto could become the world's future currency.\"\"\"\n",
        "\n",
        "for wrp in wrap(text, 150):\n",
        "  print (wrp)\n",
        "print (\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VOdyZg2rBP1"
      },
      "source": [
        "Musk tweeted that his electric vehicle-making company tesla will not accept payments in bitcoin because of environmental concerns. He also said that\n",
        "the company was working with developers of dogecoin to improve system transaction efficiency. The world's largest cryptocurrency hit a two-month low,\n",
        "while doge coin rallied by about 20 percent. Musk has in recent months often tweeted in support of crypto, but rarely for bitcoin."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScrtI0ueTFbR"
      },
      "source": [
        "## Example 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1y0EkxLXgCN"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sHMJ5ubS5Gf"
      },
      "source": [
        "http://read.gov/aesop/007.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrMhx6BAP2Ez",
        "outputId": "a988e686-b299-4234-e377-57073913c509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A Lion lay asleep in the forest, his great head resting on his paws. A timid little Mouse came upon him unexpectedly, and in her fright and haste to\n",
            "get away, ran across the Lion's nose. Roused from his nap, the Lion laid his huge paw angrily on the tiny creature to kill her.  \"Spare me!\" begged\n",
            "the poor Mouse. \"Please let me go and some day I will surely repay you.\"  The Lion was much amused to think that a Mouse could ever help him. But he\n",
            "was generous and finally let the Mouse go.  Some days later, while stalking his prey in the forest, the Lion was caught in the toils of a hunter's\n",
            "net. Unable to free himself, he filled the forest with his angry roaring. The Mouse knew the voice and quickly found the Lion struggling in the net.\n",
            "Running to one of the great ropes that bound him, she gnawed it until it parted, and soon the Lion was free.  \"You laughed when I said I would repay\n",
            "you,\" said the Mouse. \"Now you see that even a Mouse can help a Lion.\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from textwrap3 import wrap\n",
        "text = \"\"\"A Lion lay asleep in the forest, his great head resting on his paws. A timid little Mouse came upon him unexpectedly, and in her fright and haste to\n",
        "get away, ran across the Lion's nose. Roused from his nap, the Lion laid his huge paw angrily on the tiny creature to kill her.  \"Spare me!\" begged\n",
        "the poor Mouse. \"Please let me go and some day I will surely repay you.\"  The Lion was much amused to think that a Mouse could ever help him. But he\n",
        "was generous and finally let the Mouse go.  Some days later, while stalking his prey in the forest, the Lion was caught in the toils of a hunter's\n",
        "net. Unable to free himself, he filled the forest with his angry roaring. The Mouse knew the voice and quickly found the Lion struggling in the net.\n",
        "Running to one of the great ropes that bound him, she gnawed it until it parted, and soon the Lion was free.  \"You laughed when I said I would repay\n",
        "you,\" said the Mouse. \"Now you see that even a Mouse can help a Lion.\" \"\"\"\n",
        "for wrp in wrap(text, 150):\n",
        "  print (wrp)\n",
        "print (\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imbR470g15Fq"
      },
      "source": [
        "# **Summarization with T5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeiQ7_OEyHPz",
        "outputId": "2cb7c561-7f21-4531-d51f-f0b440898eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.3.0\n",
            "Uninstalling torch-2.3.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.10/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch-2.3.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? \u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (2.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from networkx->torch) (1.25.2)\n",
            "Requirement already satisfied: scipy!=1.6.1,>=1.5 in /usr/local/lib/python3.10/dist-packages (from networkx->torch) (1.13.0)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from networkx->torch) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from networkx->torch) (2.0.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->torch) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->torch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->torch) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->torch) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->torch) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->torch) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->torch) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->networkx->torch) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->networkx->torch) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->networkx->torch) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->networkx->torch) (1.16.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3127, in _compute_dependencies\n",
            "    common = types.MappingProxyType(dict.fromkeys(reqs_for_extra(None)))\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 73, in emit\n",
            "    if self.shouldRollover(record):\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 191, in shouldRollover\n",
            "    if os.path.exists(self.baseFilename) and not os.path.isfile(self.baseFilename):\n",
            "  File \"/usr/lib/python3.10/genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torch\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cXs7fnvCarm",
        "outputId": "e716e4c4-65f5-497a-c012-8465e75dcdf8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "summary_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "summary_model = summary_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzGsTUJ8TyAN"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JaEy5Xw_UMf",
        "outputId": "449daca6-525a-4c81-89d1-1fd8326bf61f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "original Text >>\n",
            "A Lion lay asleep in the forest, his great head resting on his paws. A timid little Mouse came upon him unexpectedly, and in her fright and haste to\n",
            "get away, ran across the Lion's nose. Roused from his nap, the Lion laid his huge paw angrily on the tiny creature to kill her.  \"Spare me!\" begged\n",
            "the poor Mouse. \"Please let me go and some day I will surely repay you.\"  The Lion was much amused to think that a Mouse could ever help him. But he\n",
            "was generous and finally let the Mouse go.  Some days later, while stalking his prey in the forest, the Lion was caught in the toils of a hunter's\n",
            "net. Unable to free himself, he filled the forest with his angry roaring. The Mouse knew the voice and quickly found the Lion struggling in the net.\n",
            "Running to one of the great ropes that bound him, she gnawed it until it parted, and soon the Lion was free.  \"You laughed when I said I would repay\n",
            "you,\" said the Mouse. \"Now you see that even a Mouse can help a Lion.\"\n",
            "\n",
            "\n",
            "Summarized Text >>\n",
            "A lion lay asleep in the forest, his great head resting on his paws. The timid little mouse ran across the lion's nose and begged him to let him go.\n",
            "\"please let me go and some day i will surely repay you,\" said the mouse. He was generous and finally let the mouse go; some days later, while stalking\n",
            "his prey, the lion was caught in an angry net.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def postprocesstext (content):\n",
        "  final=\"\"\n",
        "  for sent in sent_tokenize(content):\n",
        "    sent = sent.capitalize()\n",
        "    final = final +\" \"+sent\n",
        "  return final\n",
        "\n",
        "\n",
        "def summarizer(text,model,tokenizer):\n",
        "  text = text.strip().replace(\"\\n\",\" \")\n",
        "  text = \"summarize: \"+text\n",
        "  # print (text)\n",
        "  max_len = 512\n",
        "  encoding = tokenizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "  outs = model.generate(input_ids=input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  early_stopping=True,\n",
        "                                  num_beams=3,\n",
        "                                  num_return_sequences=1,\n",
        "                                  no_repeat_ngram_size=2,\n",
        "                                  min_length = 75,\n",
        "                                  max_length=300)\n",
        "\n",
        "\n",
        "  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
        "  summary = dec[0]\n",
        "  summary = postprocesstext(summary)\n",
        "  summary= summary.strip()\n",
        "\n",
        "  return summary\n",
        "\n",
        "\n",
        "summarized_text = summarizer(text,summary_model,summary_tokenizer)\n",
        "\n",
        "\n",
        "print (\"\\noriginal Text >>\")\n",
        "for wrp in wrap(text, 150):\n",
        "  print (wrp)\n",
        "print (\"\\n\")\n",
        "print (\"Summarized Text >>\")\n",
        "for wrp in wrap(summarized_text, 150):\n",
        "  print (wrp)\n",
        "print (\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0YrWTxQCo9q"
      },
      "source": [
        "# **Answer Span Extraction (Keywords and Noun Phrases)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84DxJGFn4MfD",
        "outputId": "c5632f07-b5ee-47ee-e8fc-13a7dfb1a5f6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import pke\n",
        "import traceback\n",
        "\n",
        "def get_nouns_multipartite(content):\n",
        "    out=[]\n",
        "    try:\n",
        "        extractor = pke.unsupervised.MultipartiteRank()\n",
        "        extractor.load_document(input=content,language='en')\n",
        "        #    not contain punctuation marks or stopwords as candidates.\n",
        "        pos = {'PROPN','NOUN'}\n",
        "        #pos = {'PROPN','NOUN'}\n",
        "        stoplist = list(string.punctuation)\n",
        "        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "        stoplist += stopwords.words('english')\n",
        "        # extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
        "        extractor.candidate_selection(pos=pos)\n",
        "        # 4. build the Multipartite graph and rank candidates using random walk,\n",
        "        #    alpha controls the weight adjustment mechanism, see TopicRank for\n",
        "        #    threshold/method parameters.\n",
        "        extractor.candidate_weighting(alpha=1.1,\n",
        "                                      threshold=0.75,\n",
        "                                      method='average')\n",
        "        keyphrases = extractor.get_n_best(n=15)\n",
        "\n",
        "\n",
        "        for val in keyphrases:\n",
        "            out.append(val[0])\n",
        "    except:\n",
        "        out = []\n",
        "        traceback.print_exc()\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_sRWHAd4Wwp",
        "outputId": "b7931312-ede2-4f27-8bb7-baef97562a54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keywords unsummarized:  ['lion', 'mouse', 'forest', 'net', 'paws', 'day', 'hunter', 'toils', 'roaring', 'voice', 'prey', 'nose', 'nap', 'head', 'creature']\n",
            "keywords_found in summarized:  ['net', 'lion', 'prey', 'head', 'day', 'forest', 'nose', 'paws', 'mouse']\n",
            "['lion', 'mouse', 'forest', 'net']\n"
          ]
        }
      ],
      "source": [
        "from flashtext import KeywordProcessor\n",
        "\n",
        "\n",
        "def get_keywords(originaltext,summarytext):\n",
        "  keywords = get_nouns_multipartite(originaltext)\n",
        "  print (\"keywords unsummarized: \",keywords)\n",
        "  keyword_processor = KeywordProcessor()\n",
        "  for keyword in keywords:\n",
        "    keyword_processor.add_keyword(keyword)\n",
        "\n",
        "  keywords_found = keyword_processor.extract_keywords(summarytext)\n",
        "  keywords_found = list(set(keywords_found))\n",
        "  print (\"keywords_found in summarized: \",keywords_found)\n",
        "\n",
        "  important_keywords =[]\n",
        "  for keyword in keywords:\n",
        "    if keyword in keywords_found:\n",
        "      important_keywords.append(keyword)\n",
        "\n",
        "  return important_keywords[:4]\n",
        "\n",
        "\n",
        "imp_keywords = get_keywords(text,summarized_text)\n",
        "print (imp_keywords)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXbq7b2WCaZ_"
      },
      "source": [
        "# **Question generation with T5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CuKlpL1Cj6C"
      },
      "outputs": [],
      "source": [
        "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "question_tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
        "question_model = question_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uzA4uLJ_P48",
        "outputId": "0bd5349b-3ecc-49e2-c06f-e7213dab6b1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A lion lay asleep in the forest, his great head resting on his paws. The timid little mouse ran across the lion's nose and begged him to let him go.\n",
            "\"please let me go and some day i will surely repay you,\" said the mouse. He was generous and finally let the mouse go; some days later, while stalking\n",
            "his prey, the lion was caught in an angry net.\n",
            "\n",
            "\n",
            "What animal lay asleep in the forest?\n",
            "Lion\n",
            "\n",
            "\n",
            "Who begged the lion to let him go?\n",
            "Mouse\n",
            "\n",
            "\n",
            "Where did the lion lay asleep?\n",
            "Forest\n",
            "\n",
            "\n",
            "What was the lion caught in while stalking his prey?\n",
            "Net\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_question(context,answer,model,tokenizer):\n",
        "  text = \"context: {} answer: {}\".format(context,answer)\n",
        "  encoding = tokenizer.encode_plus(text,max_length=384, pad_to_max_length=False,truncation=True, return_tensors=\"pt\").to(device)\n",
        "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
        "\n",
        "  outs = model.generate(input_ids=input_ids,\n",
        "                                  attention_mask=attention_mask,\n",
        "                                  early_stopping=True,\n",
        "                                  num_beams=5,\n",
        "                                  num_return_sequences=1,\n",
        "                                  no_repeat_ngram_size=2,\n",
        "                                  max_length=72)\n",
        "\n",
        "\n",
        "  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
        "\n",
        "\n",
        "  Question = dec[0].replace(\"question:\",\"\")\n",
        "  Question= Question.strip()\n",
        "  return Question\n",
        "\n",
        "\n",
        "\n",
        "for wrp in wrap(summarized_text, 150):\n",
        "  print (wrp)\n",
        "print (\"\\n\")\n",
        "\n",
        "for answer in imp_keywords:\n",
        "  ques = get_question(summarized_text,answer,question_model,question_tokenizer)\n",
        "  print (ques)\n",
        "  print (answer.capitalize())\n",
        "  print (\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SxnHJdf4l7-"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade httpx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfI2_yZVjWOk"
      },
      "source": [
        "# **Gradio UI Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "id": "7Ti0nc9kjsfh",
        "outputId": "d22c152a-c42c-4bc8-d27d-dd2522519159"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMPORTANT: You are using gradio version 3.9, however version 4.29.0 is available, please upgrade.\n",
            "--------\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "\n",
            "Using Embedded Colab Mode (NEW). If you have issues, please use share=True and file an issue at https://github.com/gradio-app/gradio/\n",
            "Note: opening the browser inspector may crash Embedded Colab Mode.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "(async (port, path, width, height, cache, element) => {\n                        if (!google.colab.kernel.accessAllowed && !cache) {\n                            return;\n                        }\n                        element.appendChild(document.createTextNode(''));\n                        const url = await google.colab.kernel.proxyPort(port, {cache});\n\n                        const external_link = document.createElement('div');\n                        external_link.innerHTML = `\n                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n                                    https://localhost:${port}${path}\n                                </a>\n                            </div>\n                        `;\n                        element.appendChild(external_link);\n\n                        const iframe = document.createElement('iframe');\n                        iframe.src = new URL(path, url).toString();\n                        iframe.height = height;\n                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n                        iframe.width = width;\n                        iframe.style.border = 0;\n                        element.appendChild(iframe);\n                    })(7860, \"/\", \"100%\", 500, false, window.element)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7c87defeb910>, 'http://127.0.0.1:7860/', None)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "context = gr.inputs.Textbox(lines=10, placeholder=\"Enter paragraph/content here...\")\n",
        "output = gr.outputs.HTML(  label=\"Question and Answers\")\n",
        "\n",
        "\n",
        "def generate_question(context):\n",
        "  summary_text = summarizer(context,summary_model,summary_tokenizer)\n",
        "  for wrp in wrap(summary_text, 150):\n",
        "    print (wrp)\n",
        "  np =  get_keywords(context,summary_text)\n",
        "  print (\"\\n\\nNoun phrases\",np)\n",
        "  output=\"\"\n",
        "  for answer in np:\n",
        "    ques = get_question(summary_text,answer,question_model,question_tokenizer)\n",
        "    # output= output + ques + \"\\n\" + \"Ans: \"+answer.capitalize() + \"\\n\\n\"\n",
        "    output = output + \"<b style='color:blue;'>\" + ques + \"</b>\"\n",
        "    output = output + \"<br>\"\n",
        "    output = output + \"<b style='color:green;'>\" + \"Ans: \" +answer.capitalize()+  \"</b>\"\n",
        "    output = output + \"<br>\"\n",
        "\n",
        "  summary =\"Summary: \"+ summary_text\n",
        "  for answer in np:\n",
        "    summary = summary.replace(answer,\"<b>\"+answer+\"</b>\")\n",
        "    summary = summary.replace(answer.capitalize(),\"<b>\"+answer.capitalize()+\"</b>\")\n",
        "  output = output + \"<p>\"+summary+\"</p>\"\n",
        "\n",
        "  return output\n",
        "\n",
        "iface = gr.Interface(\n",
        "  fn=generate_question,\n",
        "  inputs=context,\n",
        "  outputs=output)\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcV4uNlmApdW"
      },
      "source": [
        "# **Filter keywords with Maximum marginal Relevance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWi5WM67BLhL",
        "outputId": "ebbcd04b-01d4-4b85-d0bb-c8329fb58265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-05-08 06:29:10--  https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240508%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240508T062910Z&X-Amz-Expires=300&X-Amz-Signature=e27febe3fe545d5644f0d1c7db6b04d91529e93d85e43b3e01b4363e5190ccf0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-05-08 06:29:10--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240508%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240508T062910Z&X-Amz-Expires=300&X-Amz-Signature=e27febe3fe545d5644f0d1c7db6b04d91529e93d85e43b3e01b4363e5190ccf0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600444501 (573M) [application/octet-stream]\n",
            "Saving to: ‘s2v_reddit_2015_md.tar.gz.1’\n",
            "\n",
            "s2v_reddit_2015_md. 100%[===================>] 572.63M   116MB/s    in 6.1s    \n",
            "\n",
            "2024-05-08 06:29:16 (94.0 MB/s) - ‘s2v_reddit_2015_md.tar.gz.1’ saved [600444501/600444501]\n",
            "\n",
            "./._s2v_old\n",
            "./s2v_old/\n",
            "./s2v_old/._freqs.json\n",
            "./s2v_old/freqs.json\n",
            "./s2v_old/._vectors\n",
            "./s2v_old/vectors\n",
            "./s2v_old/._cfg\n",
            "./s2v_old/cfg\n",
            "./s2v_old/._strings.json\n",
            "./s2v_old/strings.json\n",
            "./s2v_old/._key2row\n",
            "./s2v_old/key2row\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
        "!tar -xvf  s2v_reddit_2015_md.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVBkX2IoBgd8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sense2vec import Sense2Vec\n",
        "s2v = Sense2Vec().from_disk('s2v_old')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAqN2OZbQ51Z"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "# paraphrase-distilroberta-base-v1\n",
        "sentence_transformer_model = SentenceTransformer('msmarco-distilbert-base-v3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv-FoyLEdCGE"
      },
      "outputs": [],
      "source": [
        "from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
        "normalized_levenshtein = NormalizedLevenshtein()\n",
        "\n",
        "def filter_same_sense_words(original,wordlist):\n",
        "  filtered_words=[]\n",
        "  base_sense =original.split('|')[1]\n",
        "  print (base_sense)\n",
        "  for eachword in wordlist:\n",
        "    if eachword[0].split('|')[1] == base_sense:\n",
        "      filtered_words.append(eachword[0].split('|')[0].replace(\"_\", \" \").title().strip())\n",
        "  return filtered_words\n",
        "\n",
        "def get_highest_similarity_score(wordlist,wrd):\n",
        "  score=[]\n",
        "  for each in wordlist:\n",
        "    score.append(normalized_levenshtein.similarity(each.lower(),wrd.lower()))\n",
        "  return max(score)\n",
        "\n",
        "def sense2vec_get_words(word,s2v,topn,question):\n",
        "    output = []\n",
        "    print (\"word \",word)\n",
        "    try:\n",
        "      sense = s2v.get_best_sense(word, senses= [\"NOUN\", \"PERSON\",\"PRODUCT\",\"LOC\",\"ORG\",\"EVENT\",\"NORP\",\"WORK OF ART\",\"FAC\",\"GPE\",\"NUM\",\"FACILITY\"])\n",
        "      most_similar = s2v.most_similar(sense, n=topn)\n",
        "      # print (most_similar)\n",
        "      output = filter_same_sense_words(sense,most_similar)\n",
        "      print (\"Similar \",output)\n",
        "    except:\n",
        "      output =[]\n",
        "\n",
        "    threshold = 0.6\n",
        "    final=[word]\n",
        "    checklist =question.split()\n",
        "    for x in output:\n",
        "      if get_highest_similarity_score(final,x)<threshold and x not in final and x not in checklist:\n",
        "        final.append(x)\n",
        "\n",
        "    return final[1:]\n",
        "\n",
        "def mmr(doc_embedding, word_embeddings, words, top_n, lambda_param):\n",
        "\n",
        "    # Extract similarity within words, and between words and the document\n",
        "    word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n",
        "    word_similarity = cosine_similarity(word_embeddings)\n",
        "\n",
        "    # Initialize candidates and already choose best keyword/keyphrase\n",
        "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
        "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
        "\n",
        "    for _ in range(top_n - 1):\n",
        "        # Extract similarities within candidates and\n",
        "        # between candidates and selected keywords/phrases\n",
        "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
        "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
        "\n",
        "        # Calculate MMR\n",
        "        mmr = (lambda_param) * candidate_similarities - (1-lambda_param) * target_similarities.reshape(-1, 1)\n",
        "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
        "\n",
        "        # Update keywords & candidates\n",
        "        keywords_idx.append(mmr_idx)\n",
        "        candidates_idx.remove(mmr_idx)\n",
        "\n",
        "    return [words[idx] for idx in keywords_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eigljekAu9i",
        "outputId": "f1c3b830-71a4-47b4-af6b-f0b1b0808857"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word  Bitcoin\n",
            "NOUN\n",
            "Similar  ['Bitcoin', 'Cryptocurrency', 'Bitcoins', 'Bitcoins', 'Cryptos', 'Cryptocurrencies', 'Btc', 'Digital Currency', 'Crypto Currency', 'Bit Coin', 'Fiat', 'Crypto', 'Btc.', 'Altcoin', 'Altcoins', 'Btc', 'Litecoin', 'Coinbase', 'Crypto Currencies']\n",
            "distractors  ['Cryptocurrency', 'Cryptos', 'Btc', 'Digital Currency', 'Fiat', 'Coinbase']\n",
            "['Cryptocurrency', 'Fiat', 'Coinbase', 'Btc']\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "def get_distractors_wordnet(word):\n",
        "    distractors=[]\n",
        "    try:\n",
        "      syn = wn.synsets(word,'n')[0]\n",
        "\n",
        "      word= word.lower()\n",
        "      orig_word = word\n",
        "      if len(word.split())>0:\n",
        "          word = word.replace(\" \",\"_\")\n",
        "      hypernym = syn.hypernyms()\n",
        "      if len(hypernym) == 0:\n",
        "          return distractors\n",
        "      for item in hypernym[0].hyponyms():\n",
        "          name = item.lemmas()[0].name()\n",
        "          #print (\"name \",name, \" word\",orig_word)\n",
        "          if name == orig_word:\n",
        "              continue\n",
        "          name = name.replace(\"_\",\" \")\n",
        "          name = \" \".join(w.capitalize() for w in name.split())\n",
        "          if name is not None and name not in distractors:\n",
        "              distractors.append(name)\n",
        "    except:\n",
        "      print (\"Wordnet distractors not found\")\n",
        "    return distractors\n",
        "\n",
        "def get_distractors (word,origsentence,sense2vecmodel,sentencemodel,top_n,lambdaval):\n",
        "  distractors = sense2vec_get_words(word,sense2vecmodel,top_n,origsentence)\n",
        "  print (\"distractors \",distractors)\n",
        "  if len(distractors) ==0:\n",
        "    return distractors\n",
        "  distractors_new = [word.capitalize()]\n",
        "  distractors_new.extend(distractors)\n",
        "  # print (\"distractors_new .. \",distractors_new)\n",
        "\n",
        "  embedding_sentence = origsentence+ \" \"+word.capitalize()\n",
        "  # embedding_sentence = word\n",
        "  keyword_embedding = sentencemodel.encode([embedding_sentence])\n",
        "  distractor_embeddings = sentencemodel.encode(distractors_new)\n",
        "\n",
        "  # filtered_keywords = mmr(keyword_embedding, distractor_embeddings,distractors,4,0.7)\n",
        "  max_keywords = min(len(distractors_new),5)\n",
        "  filtered_keywords = mmr(keyword_embedding, distractor_embeddings,distractors_new,max_keywords,lambdaval)\n",
        "  # filtered_keywords = filtered_keywords[1:]\n",
        "  final = [word.capitalize()]\n",
        "  for wrd in filtered_keywords:\n",
        "    if wrd.lower() !=word.lower():\n",
        "      final.append(wrd.capitalize())\n",
        "  final = final[1:]\n",
        "  return final\n",
        "\n",
        "sent = \"What cryptocurrency did Musk rarely tweet about?\"\n",
        "keyword = \"Bitcoin\"\n",
        "\n",
        "# sent = \"What did Musk say he was working with to improve system transaction efficiency?\"\n",
        "# keyword= \"Dogecoin\"\n",
        "\n",
        "\n",
        "# sent = \"What company did Musk say would not accept bitcoin payments?\"\n",
        "# keyword= \"Tesla\"\n",
        "\n",
        "\n",
        "# sent = \"What has Musk often tweeted in support of?\"\n",
        "# keyword = \"Cryptocurrency\"\n",
        "\n",
        "print (get_distractors(keyword,sent,s2v,sentence_transformer_model,40,0.2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrRPrqVDx66h",
        "outputId": "e5097a0a-82a9-4853-8c38-aca3385dd07e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Cheetah',\n",
              " 'Jaguar',\n",
              " 'Leopard',\n",
              " 'Liger',\n",
              " 'Saber-toothed Tiger',\n",
              " 'Snow Leopard',\n",
              " 'Tiger',\n",
              " 'Tiglon']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_distractors_wordnet('lion')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogiuJdRgg7V6"
      },
      "source": [
        "# **Gradio Visualization with MCQs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AC0i2ECThAqW",
        "outputId": "31855bd9-589e-4152-e6d7-cd9cf6db4efe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/inputs.py:182: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IMPORTANT: You are using gradio version 3.9, however version 4.29.0 is available, please upgrade.\n",
            "--------\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "\n",
            "Using Embedded Colab Mode (NEW). If you have issues, please use share=True and file an issue at https://github.com/gradio-app/gradio/\n",
            "Note: opening the browser inspector may crash Embedded Colab Mode.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "(async (port, path, width, height, cache, element) => {\n                        if (!google.colab.kernel.accessAllowed && !cache) {\n                            return;\n                        }\n                        element.appendChild(document.createTextNode(''));\n                        const url = await google.colab.kernel.proxyPort(port, {cache});\n\n                        const external_link = document.createElement('div');\n                        external_link.innerHTML = `\n                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n                                    https://localhost:${port}${path}\n                                </a>\n                            </div>\n                        `;\n                        element.appendChild(external_link);\n\n                        const iframe = document.createElement('iframe');\n                        iframe.src = new URL(path, url).toString();\n                        iframe.height = height;\n                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n                        iframe.width = width;\n                        iframe.style.border = 0;\n                        element.appendChild(iframe);\n                    })(7860, \"/\", \"100%\", 500, false, window.element)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elves invited a poor servant-girl to christen their first child. She stayed with them for three days, and the little men did all they could to make\n",
            "her happy. He says the girl's former masters had died, but she was still living in the mountains despite all that she had done. The boy was born in\n",
            "october, the year of her birth.\n",
            "keywords unsummarized:  ['girl', 'gold', 'elves', 'day', 'mountain', 'letter', 'master', 'invitation', 'corner', 'heap', 'broom', 'house', 'folks', 'work', 'bath']\n",
            "keywords_found in summarized:  ['elves', 'girl']\n",
            "\n",
            "\n",
            "Noun phrases ['girl', 'elves']\n",
            "Elves invited a poor servant-girl to christen their first child. She stayed with them for three days, and the little men did all they could to make\n",
            "her happy. He says the girl's former masters had died, but she was still living in the mountains despite all that she had done. The boy was born in\n",
            "october, the year of her birth.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keywords unsummarized:  ['girl', 'gold', 'elves', 'day', 'mountain', 'letter', 'master', 'invitation', 'corner', 'heap', 'broom', 'house', 'folks', 'work', 'bath']\n",
            "keywords_found in summarized:  ['elves', 'girl']\n",
            "\n",
            "\n",
            "Noun phrases ['girl', 'elves']\n",
            "word  Girl\n",
            "NOUN\n",
            "Similar  ['Chick', 'First Girl', 'Other Girl', 'Guy Friend', 'Female Friend', 'Girl', 'Girl Friend', 'Hot Guy', 'Pretty Girl', 'Beautiful Girl', 'Male Friend', 'Second Girl', 'Last Girl', 'Random Girl', 'Single Girl', 'Cute Girl', 'Boyfriend', 'Hot Girl', 'Just A Girl', 'Girlfriend', 'New Girl', 'Cute Guy', 'Boy Friend', 'Other Girls', 'Other Chick', 'Crush', 'Different Girl', 'Younger Girl', 'Really Hot Girl', 'Same Girl', 'Nice Girl', 'Cute Boy', 'Other Woman', 'Girls', 'Gf', 'Crazy Girl', 'College Girl', 'Hot Friend', 'Woman']\n",
            "distractors  ['Chick', 'First Girl', 'Other Girl', 'Guy Friend', 'Female Friend', 'Hot Guy', 'Pretty Girl', 'Beautiful Girl', 'Second Girl', 'Random Girl', 'Single Girl', 'Just A Girl', 'Crush', 'Different Girl', 'Really Hot Girl', 'Cute Boy', 'Other Woman', 'Gf', 'College Girl', 'Woman']\n",
            "word  Elves\n",
            "NOUN\n",
            "Similar  ['Dwarves', 'Orcs', 'Elves', 'Dwarves', 'High Elves', 'Dark Elves', 'Halflings', 'Elfs', 'Wood Elves', 'Orcs', 'Hobbits', 'High Elves', 'Dwarfs', 'Gnomes', 'Balrogs', 'Other Elves', 'Dark Elves', 'Daedra', 'Ancient Elves', 'Half-Orcs', 'Middle Earth', 'Night Elves']\n",
            "distractors  ['Dwarves', 'Orcs', 'High Elves', 'Halflings', 'Hobbits', 'Gnomes', 'Balrogs', 'Other Elves', 'Daedra', 'Ancient Elves', 'Half-Orcs', 'Middle Earth']\n",
            "Bob greene: a poor shoemaker cut out two pairs of shoes, and bought four pairs. He says the next morning, the shoes were made, but buyers gave him\n",
            "money to buy more - they bought them! If you want to know more, click here to get in touch with robgreene's charity st. louis jr.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keywords unsummarized:  ['shoes', 'pair', 'morning', 'shoemaker', 'leather', 'table', 'clothes', 'man', 'work', 'evening', 'men', 'woman', 'money', 'hands', 'night']\n",
            "keywords_found in summarized:  ['shoes', 'shoemaker', 'morning', 'money']\n",
            "\n",
            "\n",
            "Noun phrases ['shoes', 'morning', 'shoemaker', 'money']\n",
            "word  Shoes\n",
            "NOUN\n",
            "Similar  ['Socks', 'Sneakers', 'Tennis Shoes', 'Jeans', 'Work Shoes', 'Work Boots', 'Dress Shoes', 'Sandals', 'Nice Shoes', 'Shoes/Boots', 'Slippers', 'Footwear', 'Gym Shoes', 'Running Shoes', 'Jackets', 'Jacket', 'Flip Flops', 'Other Shoes', 'New Shoes', 'Suit Pants', 'Hiking Boots', 'Clothes', 'Underwear', 'Trousers', 'Old Shoes', 'Pants', 'Work Pants', 'Sweaters', 'Workboots', 'Leather Shoes', 'Sweatpants', 'Shoe', 'Only Shoes', 'Sweat Pants', 'Sweatshirts', 'Undies', 'Other Clothes', 'Work Clothes', 'Tights', 'Athletic Shoes']\n",
            "distractors  ['Socks', 'Sneakers', 'Tennis Shoes', 'Jeans', 'Work Shoes', 'Dress Shoes', 'Sandals', 'Shoes/Boots', 'Slippers', 'Footwear', 'Jackets', 'Flip Flops', 'Other Shoes', 'Suit Pants', 'Hiking Boots', 'Clothes', 'Underwear', 'Trousers', 'Pants', 'Sweatshirts', 'Undies', 'Tights']\n",
            "word  Morning\n",
            "NOUN\n",
            "Similar  ['Afternoon', 'Next Morning', 'Mornings', 'Evening', 'Next Day', 'Night', 'Late Afternoon', 'Early Morning', 'Most Mornings', '6:30Am', 'Midday']\n",
            "distractors  ['Afternoon', 'Next Morning', 'Evening', 'Next Day', 'Night', '6:30Am', 'Midday']\n",
            "word  Shoemaker\n",
            "PERSON\n",
            "Similar  ['Fiers', 'Arrieta', 'Paxton', 'Mchugh', 'Hammel', 'Keuchel', 'Betances', 'Wade Davis', 'Bautista', 'Liriano', 'Kluber', 'Latos', 'Wainwright', 'Utley', 'Wacha', 'Desclafani', 'Samardzija', 'Puig', 'Fister', 'Cueto', 'Cano', 'Dickey', 'Quintana', 'Peralta', 'Gausman', 'Morneau', 'Iwakuma', 'Kinsler', 'Gattis', 'Carlos Martinez', 'Stroman']\n",
            "distractors  ['Fiers', 'Arrieta', 'Paxton', 'Mchugh', 'Hammel', 'Keuchel', 'Betances', 'Wade Davis', 'Bautista', 'Liriano', 'Kluber', 'Latos', 'Wainwright', 'Utley', 'Wacha', 'Desclafani', 'Samardzija', 'Puig', 'Fister', 'Cueto', 'Cano', 'Dickey', 'Quintana', 'Peralta', 'Gausman', 'Morneau', 'Iwakuma', 'Kinsler', 'Gattis', 'Carlos Martinez', 'Stroman']\n",
            "word  Money\n",
            "NOUN\n",
            "Similar  ['Money', 'Even More Money', 'Own Money', 'Too Much Money', 'More Money', 'Little Money', 'So Much Money', 'Actual Money', 'Only Money', 'Cash', 'Own Cash', 'That Much Money', 'Huge Sums', 'Hard Earned Money', 'Extra Money', 'More Cash', 'Large Sum', 'Excess Money', 'Much Money', 'Money-', 'Single Penny', 'Enough Money', 'Just Money', 'Large Sums', 'Huge Sum', 'Other Money', 'Free Cash', 'Monies', 'Hard Earned Cash', 'Small Sum', 'Significant Money', 'Single Dollar', 'More Money', 'Free Money', 'Much More Money', 'So Much Cash', 'Way More Money', 'Additional Money', 'Hard-Earned Money', 'Fucking Money']\n",
            "distractors  ['Even More Money', 'Own Money', 'Too Much Money', 'Little Money', 'Actual Money', 'Cash', 'Own Cash', 'Huge Sums', 'Hard Earned Money', 'Large Sum', 'Excess Money', 'Single Penny', 'Free Cash', 'Small Sum', 'Significant Money', 'Single Dollar', 'So Much Cash', 'Fucking Money']\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "context = gr.inputs.Textbox(lines=10, placeholder=\"Enter paragraph/content here...\")\n",
        "output = gr.outputs.HTML(  label=\"Question and Answers\")\n",
        "radiobutton = gr.inputs.Radio([\"Wordnet\", \"Sense2Vec\"])\n",
        "\n",
        "def generate_question(context,radiobutton):\n",
        "  summary_text = summarizer(context,summary_model,summary_tokenizer)\n",
        "  for wrp in wrap(summary_text, 150):\n",
        "    print (wrp)\n",
        "  # np = getnounphrases(summary_text,sentence_transformer_model,3)\n",
        "  np =  get_keywords(context,summary_text)\n",
        "  print (\"\\n\\nNoun phrases\",np)\n",
        "  output=\"\"\n",
        "  for answer in np:\n",
        "    ques = get_question(summary_text,answer,question_model,question_tokenizer)\n",
        "    if radiobutton==\"Wordnet\":\n",
        "      distractors = get_distractors_wordnet(answer)\n",
        "    else:\n",
        "      distractors = get_distractors(answer.capitalize(),ques,s2v,sentence_transformer_model,40,0.2)\n",
        "    # output= output + ques + \"\\n\" + \"Ans: \"+answer.capitalize() + \"\\n\\n\"\n",
        "    output = output + \"<b style='color:blue;'>\" + ques + \"</b>\"\n",
        "    output = output + \"<br>\"\n",
        "    output = output + \"<b style='color:green;'>\" + \"Ans: \" +answer.capitalize()+  \"</b>\"+\"<br>\"\n",
        "    if len(distractors)>0:\n",
        "      for distractor in distractors[:4]:\n",
        "        output = output + \"<b style='color:brown;'>\" + distractor+  \"</b>\"+\"<br>\"\n",
        "    output = output + \"<br>\"\n",
        "\n",
        "  summary =\"Summary: \"+ summary_text\n",
        "  for answer in np:\n",
        "    summary = summary.replace(answer,\"<b>\"+answer+\"</b>\" + \"<br>\")\n",
        "    summary = summary.replace(answer.capitalize(),\"<b>\"+answer.capitalize()+\"</b>\")\n",
        "  output = output + \"<p>\"+summary+\"</p>\"\n",
        "  output = output + \"<br>\"\n",
        "  return output\n",
        "\n",
        "\n",
        "iface = gr.Interface(\n",
        "  fn=generate_question,\n",
        "  inputs=[context,radiobutton],\n",
        "  outputs=output)\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzD1FV_WkVlm"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
